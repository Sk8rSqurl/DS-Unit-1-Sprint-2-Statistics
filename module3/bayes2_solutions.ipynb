{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA and data handling\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import pickle\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17000, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data\n",
    "# housing_train = pd.read_csv('/content/sample_data/california_housing_train.csv')\n",
    "housing_train = pd.read_csv('california_housing_train.csv')\n",
    "housing_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the size of the dataset\n",
    "housing_train = housing_train.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14199</th>\n",
       "      <td>-122.08</td>\n",
       "      <td>37.84</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>11.7064</td>\n",
       "      <td>500001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15813</th>\n",
       "      <td>-122.41</td>\n",
       "      <td>37.70</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>2.4113</td>\n",
       "      <td>214200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6457</th>\n",
       "      <td>-118.27</td>\n",
       "      <td>34.10</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3729.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>5.7778</td>\n",
       "      <td>412700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14024</th>\n",
       "      <td>-122.04</td>\n",
       "      <td>36.96</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1438.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>4.1964</td>\n",
       "      <td>202000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13955</th>\n",
       "      <td>-122.04</td>\n",
       "      <td>38.27</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8517.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>4508.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>3.1853</td>\n",
       "      <td>129600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "14199    -122.08     37.84                17.0       1320.0           159.0   \n",
       "15813    -122.41     37.70                23.0       1817.0           400.0   \n",
       "6457     -118.27     34.10                41.0       3729.0           740.0   \n",
       "14024    -122.04     36.96                32.0       1438.0           306.0   \n",
       "13955    -122.04     38.27                16.0       8517.0          1910.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "14199      1722.0       141.0        11.7064            500001.0  \n",
       "15813      1376.0       382.0         2.4113            214200.0  \n",
       "6457       1364.0       707.0         5.7778            412700.0  \n",
       "14024       802.0       293.0         4.1964            202000.0  \n",
       "13955      4508.0      1837.0         3.1853            129600.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the data \n",
    "housing_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       500.000000\n",
       "mean     198419.628000\n",
       "std      110954.431349\n",
       "min       43600.000000\n",
       "25%      116275.000000\n",
       "50%      172650.000000\n",
       "75%      258875.000000\n",
       "max      500001.000000\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the target \n",
    "housing_train['median_house_value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the target \n",
    "housing_train['high_price']=np.where(housing_train['median_house_value']>=187250, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish the predictors and the target\n",
    "X = housing_train.drop(['median_house_value','high_price'], axis=1)\n",
    "y = housing_train['high_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of y-test: 150\n"
     ]
    }
   ],
   "source": [
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size=0.3, random_state=42 )\n",
    "print('length of y-test:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier\n",
    "mymodel = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit on the training data\n",
    "mymodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.8\n"
     ]
    }
   ],
   "source": [
    "# predict on the testing data\n",
    "y_preds = mymodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 0 0 1 0 1] true\n",
      "[0 1 1 1 0 0 0 1 0 1] predicted\n"
     ]
    }
   ],
   "source": [
    "# check out the first few houses\n",
    "print(y_test.values[:10], 'true')\n",
    "print(y_preds[:10], 'predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model performance\n",
    "print('accuracy score: ', round(metrics.accuracy_score(y_test, y_preds),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_0  pred_1\n",
       "0      72      15\n",
       "1      15      48"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the confusion matrix\n",
    "cm = pd.DataFrame(metrics.confusion_matrix(y_test, y_preds), columns=['pred_0', 'pred_1'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 48 true positives (TP): These are cases in which we predicted yes (pricey house), and it is indeed a pricey house.\n",
    "* 72 true negatives (TN): We predicted no (cheap house), and the house is indeed cheap.\n",
    "* 15 false positives (FP): We predicted yes (pricey house), but the house isn't pricey. (Also known as a \"Type I error.\")\n",
    "* 15 false negatives (FN): We predicted no (cheap house), but the house is actually pricey. (Also known as a \"Type II error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*h1EA_HjN0jSUh1y6SxdTKQ.png\" width=\"500\"/>\n",
    "</div>\n",
    "SOURCE: https://towardsdatascience.com/machine-learning-an-error-by-any-other-name-a7760a702c4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the numbers\n",
    "TN=cm['pred_0'].values[0]\n",
    "FN=cm['pred_0'].values[1]\n",
    "FP=cm['pred_1'].values[0]\n",
    "TP=cm['pred_1'].values[1]\n",
    "ALL=cm.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 72\n",
      "False Negatives: 15\n",
      "False Positives: 15\n",
      "True Positives: 48\n",
      "All: 150\n"
     ]
    }
   ],
   "source": [
    "print('True Negatives:', TN)\n",
    "print('False Negatives:', FN)\n",
    "print('False Positives:', FP)\n",
    "print('True Positives:', TP)\n",
    "print('All:', ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy:**  \n",
    "Overall, how often is it correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {round((TP + TN)/ALL, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**True Positive Rate:**   \n",
    "When it's actually yes, how often does it predict yes?        \n",
    "“Sensitivity” or “Recall”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate: 0.76\n"
     ]
    }
   ],
   "source": [
    "print(f'True Positive Rate: {round(TP/ (TP + FN), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Positive Rate:**    \n",
    "When it's actually no, how often does it predict yes?   \n",
    "Also known as \"Fall-out Rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive Rate: 0.17\n"
     ]
    }
   ],
   "source": [
    "print(f'False Positive Rate: {round(FP / (TN + FP), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision:**     \n",
    "When it predicts yes, how often is it correct?  \n",
    "Also known as \"Positive Predictive Value (PPV)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.76\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {round(TP / (TP + FP), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity:**  \n",
    "When it's actually no, how often does it predict no?    \n",
    "also known as \"True Negative Rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.83\n"
     ]
    }
   ],
   "source": [
    "print(f'Specificity: {round(TN / (TN + FP), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prevalence:**    \n",
    "How often does the yes condition actually occur in our sample?  \n",
    "actual yes/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevalence: 72.1\n"
     ]
    }
   ],
   "source": [
    "print(f'Prevalence: {round(TP + FN / ALL, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    500.000000\n",
       "mean      27.894000\n",
       "std       12.493476\n",
       "min        2.000000\n",
       "25%       17.000000\n",
       "50%       28.000000\n",
       "75%       36.000000\n",
       "max       52.000000\n",
       "Name: housing_median_age, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# House age\n",
    "housing_train['housing_median_age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a target\n",
    "housing_train['old']=np.where(housing_train['housing_median_age']>=28, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish the predictors and the target\n",
    "X = housing_train.drop(['housing_median_age','high_price', 'old'], axis=1)\n",
    "y = housing_train['old']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of y-test: 150\n"
     ]
    }
   ],
   "source": [
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size=0.3, random_state=42 )\n",
    "print('length of y-test:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier\n",
    "mymodel = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit on the training data\n",
    "mymodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the testing data\n",
    "y_preds = mymodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 1 1 0 1 0] true\n",
      "[1 1 1 0 1 0 1 0 1 0] predicted\n"
     ]
    }
   ],
   "source": [
    "# check out the first few houses\n",
    "print(y_test.values[:10], 'true')\n",
    "print(y_preds[:10], 'predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.73\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model performance\n",
    "print('accuracy score: ', round(metrics.accuracy_score(y_test, y_preds),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_0  pred_1\n",
       "0      60      24\n",
       "1      16      50"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the confusion matrix\n",
    "cm = pd.DataFrame(metrics.confusion_matrix(y_test, y_preds), columns=['pred_0', 'pred_1'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the numbers\n",
    "TN=cm['pred_0'].values[0]\n",
    "FN=cm['pred_0'].values[1]\n",
    "FP=cm['pred_1'].values[0]\n",
    "TP=cm['pred_1'].values[1]\n",
    "ALL=cm.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "True Positive Rate: 0.76\n",
      "False Positive Rate: 0.29\n",
      "Precision: 0.68\n",
      "Specificity: 0.71\n",
      "Prevalence: 50.11\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {round((TP + TN)/ALL, 2)}')\n",
    "print(f'True Positive Rate: {round(TP/ (TP + FN), 2)}')\n",
    "print(f'False Positive Rate: {round(FP / (TN + FP), 2)}')\n",
    "print(f'Precision: {round(TP / (TP + FP), 2)}')\n",
    "print(f'Specificity: {round(TN / (TN + FP), 2)}')\n",
    "print(f'Prevalence: {round(TP + FN / ALL, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology\n",
    "\n",
    "| Bayes term | Bayes formula | Confusion Matrix term | Confusion Matrix formula| Alternative CM term | \n",
    "|:-|:-|:-|:-|:-|\n",
    "| prior | P(A) | prevalence | (TP + FN) / (TP+TN+FP+FN) | ? |\n",
    "| posterior | P(A given B) | Positive Predictive Value (PPV) | TP / (TP + FP) | precision |\n",
    "| conditional | P(B given A) | True Positive Rate (TPR)  |TP / (TP + FN) | sensitivity, recall |\n",
    "| marginal | P(B) | queue rate | TP + FP | ? |  \n",
    "| prior complement | P(not A) or 100-P(A) | prevalence complement | 1-prevalence | ? |\n",
    "| ? | P(not B given not A) | True Negative Rate (TNR) | TN / (FP + TN) | specificity |\n",
    "| ? | P(B given not A) | False Positive Rate (FPR) | FP / (FP+TN) | fall-out rate, false alarm rate |\n",
    "| ? | P(not B given A) | False Negative Rate (FNR) | FN / (TP + FN) | miss rate |\n",
    "|?|?|accuracy|(TP + TN) / (TP+TN+FP+FN)|?|\n",
    "|?|?|error rate|(FP + FN) / (TP+TN+FP+FN)|misclassification rate|\n",
    "\n",
    "\n",
    "**Abbreviations**  \n",
    "A: Hypothesized Data       \n",
    "B: Observed Data         \n",
    "TP: True Positive  \n",
    "TN: True Negative  \n",
    "FP: False Positive  \n",
    "FN: False Negative  \n",
    " \n",
    "^ Note: Sometimes in Bayesian statistics the following terms are used instead:\n",
    " \n",
    "* prior = hypothesis\n",
    "* posterior = updated hypothesis\n",
    "* conditional = likelihood\n",
    "* marginal = model evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1. Drunk Drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imagine that individuals are taking a breathalyzer test with \n",
    "* an 8% false positive rate, \n",
    "* a 100% true positive rate, \n",
    "* our prior belief about drunk driving in the population is 1/1000. \n",
    "* What is the probability that a person is drunk after one positive breathalyzer test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_drunk_given_positive(prob_drunk_prior, false_positive_rate, true_positive_rate):\n",
    "    prob_non_drunk = 1 - prob_drunk_prior\n",
    "    numerator = (true_positive_rate*prob_drunk_prior)\n",
    "    denomenator = ((true_positive_rate*prob_drunk_prior) + (false_positive_rate*prob_non_drunk))\n",
    "    posterior_probability = (numerator / denomenator)\n",
    "    return posterior_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0124\n"
     ]
    }
   ],
   "source": [
    "# Probability that a person is drunk after one breathalyzer test:\n",
    "posterior = prob_drunk_given_positive(1/1000, .08, 1)\n",
    "print('{:.4f}'.format(posterior))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Marginal is provided\n",
    "Solving for the posterior is not too complicated when the marginal probability is provided for you. \n",
    "\n",
    "Suppose we have an online website where we sell a gizmo. Consider the case where a website-visitor clicks to expand the gizmo's product description. What is the probability that they will then purchase the gizmo?\n",
    "\n",
    "Let’s assume some details:  \n",
    "* 10 percent of site visitors buy the gizmo.  That's the prior: P(buy).\n",
    "* 7 percent of site visitors that purchased the gizmo also clicked on the description. That's the conditional: P(click|buy).\n",
    "* 5 percent of site visitors click on the product description. That's the marginal: P(click).\n",
    "* What percent of site visitors will purchase the gizmo after clicking on the description? That's the posterior: P(buy|click)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s plug what we know into the theorem:\n",
    "* P(A|B) = P(B|A) * P(A) / P(B)   \n",
    "* P(buy|click) = P(click|buy) * P(buy) / P(click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the prior, marginal, and conditional.\n",
    "p_a = 0.10 \n",
    "p_b = 0.05 \n",
    "p_b_given_a = 0.07 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the formula\n",
    "def bayes_w_marginal(p_a, p_b, p_b_given_a):\n",
    "    p_a_given_b = (p_b_given_a * p_a) / p_b\n",
    "    return p_a_given_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(A|B) = 14.000%\n"
     ]
    }
   ],
   "source": [
    "# plug it in\n",
    "result = bayes_w_marginal(p_a, p_b, p_b_given_a)\n",
    "print('P(A|B) = {:.3f}%'.format(result * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: No marginal provided!\n",
    "Solving for the posterior is a little harder when the marginal is not provided; most real-world problems fall into this pattern.\n",
    "\n",
    "Consider the case where we receive an email and the spam detector flags it (i.e., puts it in the spam folder). What is the probability it was actally spam?\n",
    "\n",
    "Let’s assume some details:  \n",
    "* 2 percent of the email we receive is spam -- that's the prior: P(Spam). \n",
    "* the spam detector is really good and when an email is spam, it flags it 99 percent of the time -- that's the conditional: P(Flagged|Spam).   \n",
    "* When an email is not spam, it will flag it with a very low rate of 0.1 percent -- that's the fall-out rate: P(Flagged|not Spam).  \n",
    "* What is the probability that a flagged email is actually spam? -- that's the posterior: P(Spam|Flagged) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s plug what we know into the theorem:\n",
    "* P(A|B) = P(B|A) * P(A) / P(B)   \n",
    "* P(Spam|Flagged) = P(Flagged|Spam) * P(Spam) / P(Flagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don’t know P(B), that is P(Flagged), but we can calculate it as follows:\n",
    "* P(B) = P(B|A) * P(A) + P(B|not A) * P(not A) \n",
    "* P(Flagged) = P(Flagged|Spam) * P(Spam) + P(Flagged|not Spam) * P(not Spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the prior, conditional, and fall-out rate.\n",
    "p_a = 0.02 \n",
    "p_b_given_a = 0.99 \n",
    "p_b_given_not_a = 0.001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the formula\n",
    "def bayes_no_marginal(p_a, p_b_given_a, p_b_given_not_a):\n",
    "    not_a = 1 - p_a\n",
    "    p_b = p_b_given_a * p_a + p_b_given_not_a * not_a\n",
    "    p_a_given_b = (p_b_given_a * p_a) / p_b\n",
    "    return p_a_given_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(A|B) = 95.284%\n"
     ]
    }
   ],
   "source": [
    "# plug it in\n",
    "posterior = bayes_no_marginal(p_a, p_b_given_a, p_b_given_not_a)\n",
    "print('P(A|B) = {:.3f}%'.format(posterior * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4. No marginal (again)\n",
    "What if only two pieces of information are available?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s assume some details:  \n",
    "* the condition occurs in 2% of the population -- that's the prior: P(sick). \n",
    "* when a patient is actually sick, the classifier flags them as sick 72 percent of the time -- that's the conditional: P(Flagged|Sick).   \n",
    "* when the classifier says they are not sick, this is true 97 percent of the time. That's P(not Flagged | not Sick)\n",
    "* What is the probability that a flagged patient is actually sick? -- that's the posterior: P(Sick|Flagged).\n",
    "\n",
    "We don't know the marginal P(B), and we don't know the fall-out rate -- P(Flagged|not Sick) -- but we can calculate them using the formulas:\n",
    "\n",
    "* P(B) = P(B|A) * P(A) + P(B|not A) * P(not A)\n",
    "* P(B|not A) = 1 – P(not B|not A)\n",
    "\n",
    "Which translates to: \n",
    "* P(Flagged) = P(Flagged|Sick) * P(Sick) + P(Flagged|not Sick) * P(not Sick)\n",
    "* P(Flagged|not Sick) = 1 - P(not Flagged|not Sick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the prior, conditional, and P(not B|not A).\n",
    "p_a = 0.02\n",
    "p_b_given_a = 0.72\n",
    "p_not_b_given_not_a = 0.97 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the formula:\n",
    "def bayes_no_marginal_no_fallout(p_a, p_b_given_a, p_not_b_given_not_a):\n",
    "    not_a = 1 - p_a\n",
    "    p_b_given_not_a = 1 - p_not_b_given_not_a\n",
    "    p_b = p_b_given_a * p_a + p_b_given_not_a * not_a\n",
    "    p_a_given_b = (p_b_given_a * p_a) / p_b\n",
    "    return p_a_given_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(A|B) = 32.877%\n"
     ]
    }
   ],
   "source": [
    "# plug it in:\n",
    "posterior = bayes_no_marginal_no_fallout(p_a, p_b_given_a, p_not_b_given_not_a)\n",
    "print('P(A|B) = {:.3f}%'.format(posterior * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:  \n",
    "* http://learningwithdata.com/bayes-primer.html#bayes-primer  \n",
    "* https://machinelearningmastery.com/intuition-for-bayes-theorem-with-worked-examples/  \n",
    "* https://www.bayestheorem.net/  \n",
    "* https://lucdemortier.github.io/articles/16/PerformanceMetrics\n",
    "* https://towardsdatascience.com/machine-learning-an-error-by-any-other-name-a7760a702c4d\n",
    "* https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Binary_Diagnostic_Tests-Single_Sample.pdf\n",
    "* https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\n",
    "* https://online.stat.psu.edu/stat507/node/71/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
