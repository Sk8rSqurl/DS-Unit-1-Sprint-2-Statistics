{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7OLbevlbd_Z"
   },
   "source": [
    "# Lambda School Data Science Module 123\n",
    "\n",
    "## Introduction to Bayesian Inference\n",
    "[XKCD 1132](https://www.xkcd.com/1132/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://imgs.xkcd.com/comics/frequentists_vs_bayesians.png\" width=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes vs. Frequentist inference\n",
    "\n",
    "| Bayes | Frequentist |\n",
    "|:---|:---|\n",
    "|uses probabilities for both hypotheses and data|never uses or gives the probability of a hypothesis (no prior or posterior).|\n",
    "|depends on the prior and likelihood of observed data.|depends on the likelihood P(D | H)) for both observed and unobserved data.|\n",
    "|requires one to know or construct a ‘subjective prior’.|does not require a prior.|\n",
    "|dominated statistical practice before the 20th century.|dominated statistical practice during the 20th century.|\n",
    "\n",
    "https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading20.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cookie Challenge\n",
    "https://www.greenteapress.com/thinkbayes/thinkbayes.pdf#page20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://food.fnr.sndimg.com/content/dam/images/food/fullset/2009/6/12/2/PASP09_303502_s4x3.jpg.rend.hgtvcom.826.620.suffix/1371589411856.jpeg\" width=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose there are two bowls of cookies.  \n",
    "* Bowl 1 contains 30 vanilla cookies and 10 chocolate cookies.  \n",
    "* Bowl 2 contains 20 vanilla cookies and 20 chocolate cookies.  \n",
    "\n",
    "What is the probability of randomly drawing a vanilla cookie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent probability of getting a vanilla cookie \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that I pick from bowl 1, what is the probability of randomly drawing a vanilla cookie?  \n",
    "`p(vanilla|Bowl 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose you choose one of the bowls at random and, without looking, select a cookie at random. The cookie is vanilla. What is the probability that it came from Bowl 1?  \n",
    "`p(Bowl 1|vanilla)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayes' theorem:**\n",
    "$$p(H|D) = \\frac{p(H) * p(D|H)}{p(D)}$$\n",
    "\n",
    "* H is the **hypothesis**  \n",
    "* D is the observed **data**  \n",
    "* p(H) is the probability of the hypothesis before we see the data, called the prior probability, or just **prior**.    \n",
    "* p(D) is the **marginal probability**, likelihood considered independently  \n",
    "* p(D|H) is the probability of the data under the hypothesis, called the **conditional probability**.   \n",
    "*  p(H|D) is what we want to compute, the probability of the hypothesis after we see the data, called the **posterior** probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$posterior = \\frac{prior * conditional}{marginal}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Monty Hall Challenge\n",
    "https://math.ucsd.edu/~crypto/Monty/monty.html\n",
    "\n",
    "<div>\n",
    "<img src=\"http://www.sciencemadesimple.co.uk/files/2016/04/The-choices.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's recreate the game with code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a door (A, B, C,) and a choice (KEEP, SWITCH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the game 10,000 times. Which strategy is better? (Note: comment out the 'print'!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you pick door A. The host opens door B to reveal a goat. Should you switch to door C?  \n",
    "* prior probability  = 1/3\n",
    "* marginal probability  = 1/2  \n",
    "* conditional probability =          (1/2 * 1/3)       +           ( 0 * 1/3)       +           ( 1 * 1/3) = 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your prior, marginal, and conditional probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(car is A | choice is A) = (marginal * prior) / conditional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(car is C | choice is A) = 1-P(car is A | choice is A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we pick a door and then switch after seeing another door opens, the probability of selecting the right door increases from 1/3 to 2/3. It is, based on this information, always in our best interest to switch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3mz8p08BsN6p"
   },
   "source": [
    "## Bayes' Theorem and the Bayesian mindset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fa-jzYp9i8La"
   },
   "source": [
    "### The Law of Total Probability\n",
    "\n",
    "\n",
    "By definition, the total probability of all outcomes (events) of some variable (event space) $A$ is 1. That is:\n",
    "\n",
    "$$P(A) = \\sum_n P(A_n) = 1$$\n",
    "\n",
    "The law of total probability takes this further, considering two variables ($A$ and $B$) and relating their marginal probabilities and their conditional probabilities. \n",
    "* marginal probabilities (their likelihoods considered independently, without reference to one another)\n",
    "* conditional probabilities (their likelihoods considered jointly)  \n",
    "A marginal probability is simply notated as e.g. $P(A)$, while a conditional probability is notated $P(A|B)$, which reads \"probability of $A$ *given* $B$\".\n",
    "\n",
    "The law of total probability states:\n",
    "\n",
    "$$P(A) = \\sum_n P(A | B_n) P(B_n)$$\n",
    "\n",
    "In words - the total probability of $A$ is equal to the sum of the conditional probability of $A$ on any given event $B_n$ times the probability of that event $B_n$, and summed over all possible events in $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GhycNr-Sbeie"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### The Law of Conditional Probability\n",
    "\n",
    "What's the probability of something conditioned on something else? To determine this we have to go back to set theory and think about the intersection of sets:\n",
    "\n",
    "The formula for actual calculation:\n",
    "\n",
    "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "![Visualization of set intersection](https://upload.wikimedia.org/wikipedia/commons/9/99/Venn0001.svg)\n",
    "\n",
    "Think of the overall rectangle as the whole probability space, $A$ as the left circle, $B$ as the right circle, and their intersection as the red area. Try to visualize the ratio being described in the above formula, and how it is different from just the $P(A)$ (not conditioned on $B$).\n",
    "\n",
    "We can see how this relates back to the law of total probability - multiply both sides by $P(B)$ and you get $P(A|B)P(B) = P(A \\cap B)$ - replaced back into the law of total probability we get $P(A) = \\sum_n P(A \\cap B_n)$.\n",
    "\n",
    "This may not seem like an improvement at first, but try to relate it back to the above picture - if you think of sets as physical objects, we're saying that the total probability of $A$ given $B$ is all the little pieces of it intersected with $B$, added together. The conditional probability is then just that again, but divided by the probability of $B$ itself happening in the first place.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hi45SXVyi_Wt"
   },
   "source": [
    "### Bayes Theorem\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)* P(A)}{P(B)}$$\n",
    "\n",
    "In words - the probability of $A$ conditioned on $B$ is the probability of $B$ conditioned on $A$, times the probability of $A$ and divided by the probability of $B$. \n",
    "\n",
    "\n",
    "### Using Bayes Theorem Iteratively (repeated testing)\n",
    "\n",
    "\n",
    "There are many ways to apply Bayes' theorem, such as drug tests. You may think that a drug test that is 100% accurate for true positives (detecting somebody who is a user) is pretty good, but what if it also has 1% false positive rate (indicating somebody is a user when they're not)? And furthermore, the rate of drug use in the population at large (and thus our prior belief) is 1/200.\n",
    "\n",
    "What is the likelihood somebody really is a user if they test positive? Some may guess it's 99% - the difference between the true positives and the false positives. But we have a prior belief of the background/true rate of drug use. Sounds like a job for Bayes' theorem!\n",
    "\n",
    "![Bayes Theorem Drug Test Example](https://wikimedia.org/api/rest_v1/media/math/render/svg/95c6524a3736c43e4bae139713f3df2392e6eda9)\n",
    "\n",
    "In other words, the likelihood that somebody is a user given they tested positive on a drug test is only 33.2% - probably much lower than you'd guess. This is why, in practice, it's important to use repeated testing to confirm. If we have the same individual who tested positive the first time take the drug test a second time then the posterior probability from our the first test becomes our new prior during the second application. What is the probability that a person is a drug user after two positive drug tests in a row?\n",
    "\n",
    "Bayes' theorem has been relevant in court cases where proper consideration of evidence was important. Whether it's a drug test, breathalyzer, pregnancy test, doctor's diagnosis, or neutrino detector, we have to take into account **both** the false positive rate and our prior probability in order to calculate the correct conditional probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* P(+|User) = 1 - True Positive Rate\n",
    "\n",
    "* P(User) = 1/200 Prior probability\n",
    "\n",
    "* P(+|Non-user) = False Positive rate\n",
    "\n",
    "You only need the above three numbers in order to calculate bayes rule  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior belief\n",
    "# complement of the prior belief\n",
    "# true positive rate\n",
    "# false positive rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My first iteration of Bayes Rule (Bayes Theorem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have the same person take the drug test again, and they test positive again\n",
    "# Now what is the likelihood that they are a drug user?\n",
    "# The posterior probability from the first test becomes our prior for the second iteration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the complement of that prior via the law of total probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply Bayes' theorem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the third test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn all of that into a function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htI3DGvDsRJF"
   },
   "source": [
    "## Calculating Bayesian Confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ke-5EqJI0Tsn"
   },
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bayes_mvs.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1. Using random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy and numpy\n",
    "\n",
    "# Set Random Seed for Reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FREQUENTIST APPROACH\n",
    "# calculate a 95% confidence interval on either side of this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAYESIAN APPROACH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot on graph with kernel density estimate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2. Using pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the adult workforce dataset\n",
    "url='https://raw.githubusercontent.com/ryanleeallred/datasets/master/adult.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FREQUENTIST APPROACH\n",
    "# calculate a 95% confidence interval on either side of this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAYESIAN APPROACH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot on graph with kernel density estimate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregnancy Test Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **prior** is our belief in the model given no additional information. This model could be as simple as a statistic, such as the mean we're measuring, or a complex regression.  \n",
    "The **likelihood** is the probability of the data we observed occurring given the model.   \n",
    "The **marginal probability** of the data is the probability that our data are observed regardless of what model we choose or believe in. You divide the likelihood by this value to ensure that we are only talking about our model within the context of the data occurring. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine that we have a suspicion that someone is pregnant. We might use a pregnancy test to determine whether or not that's the case. Consider the following:\n",
    "\n",
    "1) Our hypothesis, $H$, is that this person is pregnant.   \n",
    "2) A positive result on the pregnancy test is denoted as $D$.   \n",
    "3) We'll consider some \"information\" about the world: $p(H) = 0.125$  \n",
    "**prior**: on average, 12.5 percent of women are pregnant (not accurate, but useful for our purposes here).  \n",
    "**marginal**: $p(D) = 0.14$ — Fourteen percent of people who take the pregnancy test come back with a positive result.  \n",
    "**likelihood**: $p(D|H) = 0.85$ — The likelihood states, \"How likely would we get data that look like this if our hypothesis was true?\" In other words, how accurate is our test?    \n",
    "**Estimate how likely it is that a woman who got a positive result is actually be pregnant using Bayes' theorem.**  \n",
    "We've got a decent chance of the results being accurate, but not 100 percent — that means that our posterior probability of somebody being pregnant, ($H=1$), given the data that we've seen (a positive result on the test) is 0.759 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for bayes' theorem, assuming you know the conditional, prior, and marginal probabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uWgWjp3PQ3Sq"
   },
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QRgHqmYIQ9qn"
   },
   "source": [
    "- [Worked example of Bayes rule calculation](https://en.wikipedia.org/wiki/Bayes'_theorem#Examples) (helpful as it fully breaks out the denominator)\n",
    "- [Source code for mvsdist in scipy](https://github.com/scipy/scipy/blob/90534919e139d2a81c24bf08341734ff41a3db12/scipy/stats/morestats.py#L139)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_123_Introduction_to_Bayesian_Inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
